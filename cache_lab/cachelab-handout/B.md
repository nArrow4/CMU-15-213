## cache参数

s=5,b=5,E=1
也就是共有32组cache，每组一个cacheline，每个cacheline保存32字节数据
也就是每32个字节（8个int）换一组

## 32 * 32

先分析一下矩阵导入cache时的分布。
每行需要用连续的4个cacheline存储，也就是相邻两行数据的cache组号差4。
这就意味着每32/4=8行，映射的组又从第一组开始。
也就是32个cacheline，被分成8*8映射到矩阵中

为了减少miss，取数的时候尽量不要替换，所以每次最多取出32byte/4byte*32个数。
整个cache只能放下8行，后面的数又会从第一行开始映射，所以分块的行数为8（取9行的话，第九行会覆盖第一行）
每个cacheline能放下8个数，所以列数为8的倍数（最多32）

根据以上思路，按8\*8分块转置，理论上一块的miss为8+8=16，总共4\*4\*16=256次miss。
但是实现之后跑出来343次。
简单分析一下，发现在矩阵A的对角线处，都会发生miss（对角线上的数据映射到同一行），每个对角线上的值带来两次miss，共32\*2=64次，加上之前分析的为256+64=320次。
多出来的miss可能是函数调用之类的开销。

解决思路就是，每次load A中8个数的时候，先保存到栈中，这样就不存在load一次A再load一次B的情况了。优化之后的理论miss为343-64=279。
实际测出来为287，原因（或许）是因为用优化的方法会带来8个额外的栈开销（8个变量）

## 61*67

每行需要8组来存，最多读4行。
8*8分块跑出来2118，但是理论上为8\*67+9\*61=1085。
尝试按照之前的思路分析使用4*8的分块，2462。
miss反而增多了，想了一下发现4*8在A的视角是好的，但是转置到B就变成8\*4了，行数大于4会造成很多额外的miss。
后来看网上一些博客，发现16*16可以混过去。就没继续想了。

## 64*64

4\*4利用率太低（导致需要load更多次，miss自然就增多了），8\*8行数太多也带来了额外的miss。
所以理想的分块是4*8,但是转置之后变成8\*4，仍然造成额外miss，参照网上的博客，采用一种“暂留”的方法。
也就是4\*8的左边的4\*4直接拷贝到转置矩阵，右边的4\*4既然已经考出来了，就先存到B的某个位置，后续直接从B中取出，放到正确的位置。
也就是第一个4\*4不用修正，其余位置的4\*4都需要先把当前位置的值挪到正确的位置，再去从A中导入结果。
推荐一篇[博客](https://www.cnblogs.com/liqiuhao/p/8026100.html)，讲的很详细。